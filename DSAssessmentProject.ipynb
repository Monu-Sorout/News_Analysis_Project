{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24mF9snP7Izr",
        "outputId": "6024e321-2053-4a93-f74f-79bfd85547ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the URL of a news article: https://www.timesnownews.com/entertainment-news/bollywood/explained-how-zakir-hussain-went-from-tabla-prodigy-to-global-musical-icon-article-116343244\n",
            "\n",
            "Scraping article...\n",
            "Article successfully scraped!\n",
            "Explained: How Zakir Hussain Went From Tabla Prodigy To Global Musical Icon\n",
            "\n",
            "Theme Entertainment Bollywood Box Office Reviews TV Web Series Hollywood Korean Telugu Tamil Kannada Malayalam Movies Bollywood Box Office Reviews TV Web Series Hollywood Korean Telugu Tamil Kannada Malayalam Movies Trending: news entertainment bollywood Updated Dec 16, 2024, 08:34 IST Tabla maestro Zakir Hussain was battling heart-related problems Trending: An introvert with a keen interest in book reading and binge wa...\n",
            "\n",
            "Extracting entities...\n",
            "Entities extracted:\n",
            "Persons: {'Bennett', 'RomCom', 'Tamil Kannada', 'Tabla maestro Zakir Hussain'}\n",
            "Organizations: {'Bollywood-Hollywood'}\n",
            "\n",
            "Analyzing sentiment...\n",
            "Sentiment of the article: Positive\n",
            "\n",
            "Storing results in database...\n",
            "Data successfully stored in the database.\n"
          ]
        }
      ],
      "source": [
        "# Install necessary libraries\n",
        "# !pip install requests beautifulsoup4 spacy textblob sqlalchemy pandas\n",
        "# !python -m spacy download en_core_web_sm\n",
        "\n",
        "# Import necessary libraries\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import spacy\n",
        "from textblob import TextBlob\n",
        "import pandas as pd\n",
        "from sqlalchemy import create_engine\n",
        "\n",
        "# Task 1: Data Scraping\n",
        "def scrape_article(url: str) -> str:\n",
        "    \"\"\"\n",
        "    Fetches and extracts the main text content of a news article from the given URL.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Ensure URL starts with http/https\n",
        "        if not url.startswith(('http://', 'https://')):\n",
        "            url = f\"https://{url}\"\n",
        "\n",
        "        # Make a request to the URL\n",
        "        response = requests.get(url, timeout=10)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        # Parse the HTML\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        # Extract the title and paragraphs\n",
        "        title = soup.find('h1').get_text(strip=True) if soup.find('h1') else \"No Title Found\"\n",
        "        paragraphs = soup.find_all('p')\n",
        "        content = \" \".join(para.get_text(strip=True) for para in paragraphs)\n",
        "\n",
        "        # Check if content exists\n",
        "        if not content.strip():\n",
        "            return \"No content found in the article.\"\n",
        "\n",
        "        return f\"{title}\\n\\n{content}\"\n",
        "    except requests.exceptions.MissingSchema:\n",
        "        return \"Invalid URL format. Please include http:// or https:// in the URL.\"\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        return f\"Error fetching the article: {e}\"\n",
        "    except Exception as e:\n",
        "        return f\"An unexpected error occurred: {e}\"\n",
        "\n",
        "# Task 2: Entity Extraction\n",
        "def extract_entities(text):\n",
        "    \"\"\"Extract PERSON and ORG entities using Spacy's Named Entity Recognition (NER).\"\"\"\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "    doc = nlp(text)\n",
        "    entities = {\"PERSON\": set(), \"ORG\": set()}\n",
        "    for ent in doc.ents:\n",
        "        if ent.label_ in entities:\n",
        "            entities[ent.label_].add(ent.text)\n",
        "    return entities\n",
        "\n",
        "# Task 3: Sentiment Analysis\n",
        "def analyze_sentiment(text):\n",
        "    \"\"\"Classify the sentiment of the text as positive, negative, or neutral.\"\"\"\n",
        "    analysis = TextBlob(text)\n",
        "    polarity = analysis.sentiment.polarity\n",
        "    if polarity > 0:\n",
        "        return \"Positive\"\n",
        "    elif polarity < 0:\n",
        "        return \"Negative\"\n",
        "    else:\n",
        "        return \"Neutral\"\n",
        "\n",
        "# Task 4: Storage\n",
        "def store_in_database(url, article_text, entities, sentiment):\n",
        "    \"\"\"Store the scraped data, entities, and sentiment analysis results into a database.\"\"\"\n",
        "    try:\n",
        "        # Define a SQLite database\n",
        "        engine = create_engine('sqlite:///articles.db')\n",
        "        connection = engine.connect()\n",
        "\n",
        "        # Prepare the data\n",
        "        data = {\n",
        "            \"URL\": [url],\n",
        "            \"Text\": [article_text],\n",
        "            \"Persons\": [', '.join(entities[\"PERSON\"])],\n",
        "            \"Organizations\": [', '.join(entities[\"ORG\"])],\n",
        "            \"Sentiment\": [sentiment]\n",
        "        }\n",
        "        df = pd.DataFrame(data)\n",
        "\n",
        "        # Store the data\n",
        "        df.to_sql('articles', con=engine, if_exists='append', index=False)\n",
        "        print(\"Data successfully stored in the database.\")\n",
        "    except Exception as e:\n",
        "        print(\"Error occurred while storing data in the database:\", e)\n",
        "\n",
        "# Task 5: Integrating and Testing\n",
        "def main():\n",
        "    url = input(\"Enter the URL of a news article: \")\n",
        "    print(\"\\nScraping article...\")\n",
        "    article_text = scrape_article(url)\n",
        "\n",
        "    if article_text.startswith(\"Error\") or article_text.startswith(\"Invalid\"):\n",
        "        print(article_text)  # Display the error message\n",
        "        return\n",
        "\n",
        "    print(\"Article successfully scraped!\")\n",
        "    print(article_text[:500] + '...')  # Show the first 500 characters of the article for brevity\n",
        "\n",
        "    print(\"\\nExtracting entities...\")\n",
        "    entities = extract_entities(article_text)\n",
        "    print(\"Entities extracted:\")\n",
        "    print(\"Persons:\", entities[\"PERSON\"])\n",
        "    print(\"Organizations:\", entities[\"ORG\"])\n",
        "\n",
        "    print(\"\\nAnalyzing sentiment...\")\n",
        "    sentiment = analyze_sentiment(article_text)\n",
        "    print(\"Sentiment of the article:\", sentiment)\n",
        "\n",
        "    print(\"\\nStoring results in database...\")\n",
        "    store_in_database(url, article_text, entities, sentiment)\n",
        "\n",
        "# Run the main function\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ]
}